{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Flatten, BatchNormalization, Dropout\nfrom tensorflow.keras.applications import InceptionV3\nfrom glob import glob\nfrom imageio import imwrite","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"/kaggle/input/dataset/dataset_dr/dataset_dr\"\nbatch_size =32\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=(227, 227),\n    batch_size=batch_size,\n    seed=1,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n    data_dir, # same directory as training data\n    target_size=(227, 227),\n    batch_size=batch_size,\n    seed=1,\n    class_mode='categorical',\n    subset='validation') # ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('/kaggle/input/ml-cybersec/model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To retrieve full dataset from the Image Generators\nvalidation_generator.reset()\nx_test, y_test = next(validation_generator)\nfor i in range(int(len(validation_generator))-1):\n    image, label = next(validation_generator)\n    x_test = np.append(x_test, image, axis=0)\n    y_test = np.append(y_test, label, axis=0)\nprint(x_test.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FGSM Untargeted","metadata":{}},{"cell_type":"code","source":"def fgsm_untargeted(image, label):\n    image = tf.cast(image, tf.float32)\n    label = np.expand_dims(label, axis = 0)\n#     print(label.shape)\n    with tf.GradientTape() as tape:\n        tape.watch(image)\n        prediction = model(image)\n        loss = tf.keras.losses.CategoricalCrossentropy()(label, prediction)\n    # calculate gradident for loss function with repsect to image\n    gradient = tape.gradient(loss, image)\n    # only take the sign of each loss gradient\n    signed_grad = tf.sign(gradient)\n    \n    return signed_grad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def peek_pert(i = 0, untargted = 1):\n    # use ith image from test dataset to generate a perturbation pattern\n    image = x_test[i]\n    label = y_test[i]\n\n    if untargted:\n        perturbations = fgsm_untargeted(image.reshape((1, 227, 227, 3)), label)\n    else:\n        perturbations = fgsm_targeted(image.reshape((1, 227, 227, 3)), label)\n\n    # show perturbation pattern\n    plt.figure()\n    plt.imshow(perturbations.numpy().reshape(227,227,3))\n    plt.title('Perturbation Pattern')\n    plt.savefig('fgsm_perturbation_pattern.png')\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def peek_adv(i = 0, e = 0.1, untargeted = 1):\n    # FGSM adversarial attack on the sample image\n    # ith image in test set, 0<=i<10000\n    # e: epsilon\n    image = x_test[i]\n    label = y_test[i]\n    if untargeted:\n        perturbations = fgsm_untargeted(image.reshape((1, 227, 227, 3)), label).numpy()\n        adversarial = image + perturbations * e\n    else: \n        perturbations = fgsm_targeted(image.reshape((1, 227, 227, 3)), label).numpy()\n        adversarial = image - perturbations * e\n\n    print(f'Actual label: ', tf.keras.backend.argmax(model(image.reshape((1, 227, 227, 3)))).numpy()[0])\n    print(f'Prediction: ', tf.keras.backend.argmax(model(adversarial)).numpy()[0])\n\n    plt.imshow(adversarial.reshape((227, 227, 3)))\n    plt.savefig('fgsm_perturbed_image.png')\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# peek_pert(i = 200, untargted = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# peek_adv(i = 200, e = 0.1, untargeted = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(epsilon, untargeted = 1):\n    miss, hit = 0, 0\n    \n    for i in range(731):\n        image = x_test[i]\n        label = y_test[i]\n\n        if untargeted:\n            perturbations = fgsm_untargeted(image.reshape((1, 227, 227, 3)), label).numpy()\n            adversarial = image + perturbations * epsilon\n        else:\n            perturbations = fgsm_targeted(image.reshape((1, 227, 227, 3)), label).numpy()\n            adversarial = image - perturbations * epsilon\n\n        truth = tf.keras.backend.argmax(model(image.reshape((1, 227, 227, 3)))).numpy()[0]\n        pred = tf.keras.backend.argmax(model(adversarial)).numpy()[0]\n\n        if truth != pred:\n            miss += 1\n        else:\n            hit += 1\n\n    print(f'Epsilon: {epsilon}, test accuracy = {hit} / 10000 = {(hit/731)*100}%')\n    return (hit/731)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epsilons = [1/255, 5/255, 10/255, 15/255, 20/255]\naccuracies_untargeted = []\nfor eps in epsilons:\n    acc = test(eps, untargeted = 1)\n    accuracies_untargeted.append(acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Original test accuracy\n# model.evaluate(x_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracies_untargeted","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epsilons_plot = [0] + epsilons\nepsilons_plot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracies_untargeted_plots = [83.33] + accuracies_untargeted\naccuracies_untargeted_plots","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set_style('darkgrid') \nplt.rc('axes', titlesize=18)     # fontsize of the axes title\nplt.rc('axes', labelsize=14)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=13)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=13)    # fontsize of the tick labels\nplt.rc('legend', fontsize=13)    # legend fontsize\nplt.rc('font', size=13)          # controls default text sizes\n\nplt.figure(figsize=(5,5))\nplt.plot(epsilons_plot, accuracies_untargeted_plots, \"+-\")\nplt.title(\"Accuracy vs Epsilon\")\nplt.xlabel(\"Epsilon\")\nplt.ylabel(\"Accuracy\")\nplt.savefig('fgsm_accuracy_with_epsilon_plot.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterative FGS (BIM)","metadata":{}},{"cell_type":"code","source":"figure = plt.figure(figsize=(10,8))\ncols, rows = 3,3\nfor i in range(1, cols*rows+1):\n    index = np.random.randint(x_test.shape[0], size=1)\n    img, label = (x_test[index], y_test[index])\n    figure.add_subplot(rows, cols, i)\n    plt.title(\"true label: {}\".format(label))\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze(), cmap=\"gray\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_perturb_untarget_im_iter(iteration, model, X, Y, epislon):\n    x_perturb = [] \n    x_tensor = tf.convert_to_tensor(X, dtype=tf.float32)\n    for i in range(iteration):\n        with tf.GradientTape() as tape:\n            tape.watch(x_tensor)\n            pred = model(x_tensor)\n            loss = tf.keras.losses.CategoricalCrossentropy()(Y, pred)\n        grad = tape.gradient(loss, x_tensor)\n        grad_sign = tf.sign(grad)\n        x_tensor = tf.clip_by_value((x_tensor + epislon * grad_sign), clip_value_min = 0, clip_value_max = 1)\n    x_perturb.append(x_tensor)\n    return x_perturb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_perturb = generate_perturb_untarget_im_iter(35, model, x_test[:100], y_test[:100], 1/255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Original test accuracy\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Test accuracy on perturbed images\nmodel.evaluate(x_perturb, y_test[:100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(10,8))\n# index = np.random.randint(x_test[:100].shape[0], size=1)\nindex = [76]\nimg1, label1 = (x_test[index], y_test[index])\nfigure.add_subplot(1, 2, 1)\nplt.title(\"Original Image\")\nplt.axis(\"off\")\nplt.imshow(img1.squeeze(), cmap=\"gray\")\nimg2, label2 = (np.array(x_perturb[0][index[0]]), y_test[index])\nfigure.add_subplot(1, 2, 2)\nplt.title(\"Perturbed Image\")\nplt.axis(\"off\")\nplt.imshow(img2.squeeze(), cmap=\"gray\")\nplt.savefig('BIM_original_with_perturbed_iterations35.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PGD","metadata":{}},{"cell_type":"code","source":"iterations = 20\nalpha = 2\nepsilon = 1/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imwrite('/kaggle/working/'+\"1002\"+'_gen_img.png',np.clip(np.expand_dims(x_test[0], axis=0), 0, 255).astype('uint8'))\n# print(x_test[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #pgd_generation\nimage_count = 0\nperturbed_images_pgd = []\n# flag = 0\norig_label = []\nfor i in range(len(y_test[:15])):\n    print(i)\n    gen_img = tf.identity(x_test[i])\n    gen_img = gen_img + tf.random.uniform(gen_img.get_shape().as_list(), minval=-epsilon, maxval=epsilon, dtype=tf.dtypes.float32)\n#     x_temp = x_test[i].numpy()\n    for iters in range(iterations):\n        imgv = tf.Variable(gen_img)\n        imgv = tf.reshape(imgv, [1,227, 227, 3])\n        with tf.GradientTape() as tape:\n            tape.watch(imgv)\n            predictions = model(imgv)\n#             print(type(y_test[i]), type(predictions))\n            y_test_tf = tf.convert_to_tensor(y_test[i], np.float32)\n            y_test_tf = tf.expand_dims(y_test_tf, axis=0)\n            loss = tf.keras.losses.CategoricalCrossentropy()(y_test_tf, predictions)\n            grads = tape.gradient(loss,imgv)\n        signed_grads = tf.sign(grads)\n        gen_img = gen_img + (alpha*signed_grads)\n        gen_img = tf.clip_by_value(gen_img, x_test[i]-epsilon, x_test[i]+epsilon)\n#     for i in range(16):\n#         image_count += 1\n#     if image_count>200:\n#         flag = 1\n#         break\n    image_count += 1\n    orig_label.append(y_test[i])\n    gen_image = gen_img.numpy()*255\n    gen_image = np.squeeze(gen_image, axis=0)\n    perturbed_images_pgd.append(gen_image)\n    orig_image = x_test[i]*255\n#         print(gen_image.shape, orig_image.shape)\n    imwrite('/kaggle/working/'+str(image_count)+'_gen_img.png',np.clip(gen_image, 0, 255).astype('uint8'))\n#     imwrite('/kaggle/working/'+str(image_count)+'_orig_img.png',np.clip(orig_image, 0, 255).astype('uint8'))\n#     if flag==1:\n#         break ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2\n# generated_images = []\n# for i in range(1, len(y_test)+1):\n#     x = cv2.imread('/kaggle/working/'+str(i)+'_gen_img.png')\n#     generated_images.append(x)\n# generated_images = tf.convert_to_tensor(generated_images)\n# orig_label = tf.convert_to_tensor(orig_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# original_images = []\n# for i in range(1, len(y_test)+1):\n#     x = cv2.imread('/kaggle/working/'+str(i)+'_orig_img.png')\n#     original_images.append(x)\n# original_images = tf.convert_to_tensor(generated_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perturbed_images_pgd_clipped = np.clip(perturbed_images_pgd, 0, 255)\nperturbed_images_pgd_clipped","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perturbed_images_pgd_clipped.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perturbed_images_pgd_clipped[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimg = Image.fromarray(perturbed_images_pgd_clipped[0], 'RGB')\nimg.save('my.png')\nimg.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# orig_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(perturbed_images_pgd_clipped, y_test, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CW","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n\n__all__ = ['cw']\n\ndef cw(model, x, y=None, eps=1.0, ord_=2, T=2,\n       optimizer=tf.optimizers.Adam(learning_rate=0.1), alpha=0.9,\n       min_prob=0, clip=(0.0, 1.0)):\n    \n    xshape = x.get_shape().as_list()\n    noise = tf.compat.v1.get_variable('noise', xshape, tf.float32,\n                            initializer=tf.initializers.zeros)\n\n    # scale input to (0, 1)\n    x_scaled = (x - clip[0]) / (clip[1] - clip[0])\n\n    # change to sigmoid-space, clip to avoid overflow.\n    z = tf.clip_by_value(x_scaled, 1e-8, 1-1e-8)\n    xinv = tf.compat.v1.log(z / (1 - z)) / T\n\n    # add noise in sigmoid-space and map back to input domain\n    xadv = tf.sigmoid(T * (xinv + noise))\n    xadv = xadv * (clip[1] - clip[0]) + clip[0]\n\n    ybar, logits = model(xadv, logits=True)\n    ydim = ybar.get_shape().as_list()[1]\n\n    if y is not None:\n        y = tf.cond(tf.equal(tf.rank(y), 0),\n                    lambda: tf.fill([xshape[0]], y),\n                    lambda: tf.identity(y))\n    else:\n        # we set target to the least-likely label\n        y = tf.argmin(ybar, axis=1, output_type=tf.int32)\n\n    mask = tf.one_hot(y, ydim, on_value=0.0, off_value=float('inf'))\n    yt = tf.reduce_max(logits - mask, axis=1)\n    yo = tf.reduce_max(logits, axis=1)\n\n    # encourage to classify to a wrong category\n    loss0 = tf.nn.relu(yo - yt + min_prob)\n\n    axis = list(range(1, len(xshape)))\n    ord_ = float(ord_)\n\n    # make sure the adversarial images are visually close\n    if 2 == ord_:\n        # CW-L2 Original paper uses the reduce_sum version.  These two\n        # implementation does not differ much.\n\n        # loss1 = tf.reduce_sum(tf.square(xadv-x), axis=axis)\n        loss1 = tf.reduce_mean(tf.square(xadv-x))\n    else:\n        # CW-Linf\n        tau0 = tf.fill([xshape[0]] + [1]*len(axis), clip[1])\n        tau = tf.get_variable('cw8-noise-upperbound', dtype=tf.float32,\n                              initializer=tau0, trainable=False)\n        diff = xadv - x - tau\n\n        # if all values are smaller than the upper bound value tau, we reduce\n        # this value via tau*0.9 to make sure L-inf does not get stuck.\n        tau = alpha * tf.to_float(tf.reduce_all(diff < 0, axis=axis))\n        loss1 = tf.nn.relu(tf.reduce_sum(diff, axis=axis))\n\n    loss = eps*loss0 + loss1\n    train_op = optimizer.minimize(loss, var_list=[noise])\n\n    # We may need to update tau after each iteration.  Refer to the CW-Linf\n    # section in the original paper.\n    if 2 != ord_:\n        train_op = tf.group(train_op, tau)\n\n    return train_op, xadv, noise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_tf = tf.convert_to_tensor(x_test[:100])\ny_test_tf = tf.convert_to_tensor(y_test[:100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_op, xadv, noise = cw(model, x_test_tf, y_test_tf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(xadv, y_test, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adversarial Retraining","metadata":{}},{"cell_type":"code","source":"iterations = 35\nalpha = 2\nepsilon = 8/255\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To retrieve full training dataset from the Image Generators\ntrain_generator.reset()\nx_train, y_train = next(train_generator)\nfor i in range(int(len(train_generator))-1):\n    image, label = next(train_generator)\n    x_train = np.append(x_train, image, axis=0 )\n    y_train = np.append(y_train, label, axis=0)\nprint(x_train.shape, y_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating perturbed training images. Taking perturbed test images from the previous section.\nimage_count = 0\norig_label_train = []\nfor i in range(len(y_train)):\n    gen_img = tf.identity(x_train[i])\n    gen_img = gen_img + tf.random.uniform(gen_img.get_shape().as_list(), minval=-epsilon, maxval=epsilon, dtype=tf.dtypes.float32)\n    for iters in range(iterations):\n        imgv = tf.Variable(gen_img)\n        imgv = tf.reshape(imgv, [1,227, 227, 3])\n        with tf.GradientTape() as tape:\n            tape.watch(imgv)\n            predictions = model(imgv)\n#             print(type(y_test[i]), type(predictions))\n            y_train_tf = tf.convert_to_tensor(y_train[i], np.float32)\n            y_train_tf = tf.expand_dims(y_train_tf, axis=0)\n            loss = tf.keras.losses.CategoricalCrossentropy()(y_train_tf, predictions)\n            grads = tape.gradient(loss,imgv)\n        signed_grads = tf.sign(grads)\n        gen_img = gen_img + (alpha*signed_grads)\n        gen_img = tf.clip_by_value(gen_img, x_train[i]-epsilon, x_train[i]+epsilon)\n#     for i in range(16):\n#         image_count += 1\n#         if image_count>200:\n#             flag = 1\n#             break\n    image_count += 1\n    orig_label_train.append(y_train[i])\n    gen_image = gen_img.numpy()*255\n    gen_image = np.squeeze(gen_image, axis=0)\n    orig_image = x_train[i]*255\n#         print(gen_image.shape, orig_image.shape)\n    imwrite('/kaggle/working/'+str(image_count)+'_gen_img_train.png',np.clip(gen_image, 0, 255).astype('uint8'))\n    imwrite('/kaggle/working/'+str(image_count)+'_orig_img_train.png',np.clip(orig_image, 0, 255).astype('uint8'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generated_images_train = []\n# for i in range(1, len(y_train)+1):\n#     x = cv2.imread('/kaggle/working/'+str(i)+'_gen_img_train.png')\n#     generated_images_train.append(x)\n# generated_images_train = tf.convert_to_tensor(generated_images)\n# orig_label_train = tf.convert_to_tensor(orig_label_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_final = tf.concat([x_train, generated_images_train], 0)\n# y_final = tf.concat([y_train, y_train], 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IncV3 = InceptionV3(include_top = False, weights = \"imagenet\",input_shape = (227,227,3))\nmodel_adv = Sequential()\n\nmodel_adv.add(IncV3)\nmodel_adv.add(Flatten())\n\nmodel_adv.add(Dense(units = 2048, activation = \"relu\"))\nmodel_adv.add(Dropout(0.5))\nmodel_adv.add(Dense(units = 5, activation = \"softmax\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_adv.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nb_epochs = 100\n# model.fit(\n#     train_generator,\n#     steps_per_epoch = train_generator.samples // batch_size,\n#     validation_data = validation_generator, \n#     validation_steps = validation_generator.samples // batch_size,\n#     epochs = nb_epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_adv.fit(x_final, y_final, epochs = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e = 125/255\n# Here, eps/28 is being used to give the effect of binding. Where 28 comes from sqrt(N*N) = sqrt(28*28)\n# To store the adverserially perturbed train images.\nx_train_perturbed = []\n\nfor i in range(2931):\n    image = x_train[i]\n    label = y_train[i]\n    \n    perturbations = fgsm_untargeted(image.reshape((1, 227, 227, 3)), label).numpy()\n    adversarial = tf.clip_by_value((image + perturbations * e), clip_value_min = 0, clip_value_max = 1)\n    adversarial = adversarial.numpy()\n    x_train_perturbed.append(adversarial)\n    \nx_train_perturbed = np.asarray(x_train_perturbed).reshape((2931,227,227,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e = 125/255\nx_test_perturbed = []\nfor i in range(731):\n    image = x_test[i]\n    label = y_test[i]\n    perturbations = fgsm_untargeted(image.reshape((1, 227, 227, 3)), label).numpy()\n    adversarial = tf.clip_by_value((image + perturbations * e), clip_value_min = 0, clip_value_max = 1)\n    adversarial = adversarial.numpy()\n    x_test_perturbed.append(adversarial)\n    \nx_test_perturbed = np.asarray(x_test_perturbed).reshape((731,227,227,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving this array for a different experiment.\nwith open('perturbed_images.npy', 'wb') as f:\n    np.save(f, x_test_perturbed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_final = tf.concat([x_train, x_train_perturbed], 0)\ny_final = tf.concat([y_train, y_train], 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_adv.fit(x_final, y_final, epochs = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_adv.evaluate(x_test,  y_test, verbose = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_adv.evaluate(x_test_perturbed,  y_test, verbose = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}